# 玩转HF/魔搭/魔乐社区

## Hugging Face
1. 官网：https://huggingface.co/ 
2. 通过 models 搜索模型

![img.png](images/img.png)


## GitHub CodeSpace
1. 网址：https://github.com/codespaces
2. 使用 Jupyter Notebook
3. 安装依赖
   ```shell
    # 安装 transformers
    pip install transformers==4.38
    pip install sentencepiece==0.1.99
    pip install einops==0.8.0
    pip install protobuf==5.27.2
    pip install accelerate==0.33.0
    ```
4. 下载配置文件
    ```shell
    touch hf_download_josn.py
    ```
    
    ```python
    import os
    from huggingface_hub import hf_hub_download
    
    # 指定模型标识符
    repo_id = "internlm/internlm2_5-7b"
    
    # 指定要下载的文件列表
    files_to_download = [
        {"filename": "config.json"},
        {"filename": "model.safetensors.index.json"}
    ]
    
    # 创建一个目录来存放下载的文件
    local_dir = f"{repo_id.split('/')[1]}"
    os.makedirs(local_dir, exist_ok=True)
    
    # 遍历文件列表并下载每个文件
    for file_info in files_to_download:
        file_path = hf_hub_download(
            repo_id=repo_id,
            filename=file_info["filename"],
            local_dir=local_dir
        )
    print(f"{file_info['filename']} file downloaded to: {file_path}")
   ```    

   ```shell
    python hf_download_josn.py
    ```
   ![img_1.png](images/img_1.png)
5. 下载完整文件
   ```shell
   touch hf_download_1_8_demo.py
   ```
   
   ```python
   import torch
   from transformers import AutoTokenizer, AutoModelForCausalLM
   
   tokenizer = AutoTokenizer.from_pretrained("internlm/internlm2_5-1_8b", trust_remote_code=True)
   model = AutoModelForCausalLM.from_pretrained("internlm/internlm2_5-1_8b", torch_dtype=torch.float16, trust_remote_code=True)
   model = model.eval()
   
   inputs = tokenizer(["A beautiful flower"], return_tensors="pt")
   gen_kwargs = {
       "max_length": 128,
       "top_p": 0.8,
       "temperature": 0.8,
       "do_sample": True,
       "repetition_penalty": 1.0
   }
   
   # 以下内容可选，如果解除注释等待一段时间后可以看到模型输出
   # output = model.generate(**inputs, **gen_kwargs)
   # output = tokenizer.decode(output[0].tolist(), skip_special_tokens=True)
   # print(output)
   ```
   
   ```shell
   python hf_download_1_8_demo.py
   ```
   
   ![img_4.png](images/img_4.png)


## Hugging Face Spaces
网址： https://huggingface.co/spaces


### 创建项目
![img_2.png](images/img_2.png)

![img_3.png](images/img_3.png)


### 克隆项目
```shell
cd /workspaces/codespaces-jupyter
git clone https://huggingface.co/spaces/KitHung/intern_cobuild
cd /workspaces/codespaces-jupyter/intern_cobuild
```


### push 到远程仓库
```shell
git add .
git commit -m "update: colearn page"
git push
```

### 刷新 space 页面
![img_7.png](images/img_7.png)



#### 报错处理
报错信息：

remote: Password authentication in git is no longer supported. You must use a user access token or an SSH key instead. See https://huggingface.co/blog/password-git-deprecation
fatal: Authentication failed for 'https://huggingface.co/spaces/KitHung/intern_cobuild/'

解决方案：
获取 token 并进行项目验证

1. 获取 token
   Settings -> Access Tokens -> Create new token
   
   ![img_5.png](images/img_5.png)
2. 添加验证并再次 push
```shell
git remote set-url origin https://<user_name>:<token>@huggingface.co/<repo_path>
例如：
git remote set-url origin https://jack:hf_xxxxx@huggingface.co/spaces/jack/intern_cobuild/
git push
```

![img_6.png](images/img_6.png)


### 模型上传
```shell
# 安装 git lfs 支持大文件系统
curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash
# sudo apt-get install git-lfs # CodeSpace里面可能会有aptkey冲突且没有足够权限
git lfs install # 直接在git环境下配置git LFS
pip install huggingface_hub
```

#### 登录
```shell
git config --global credential.helper store
huggingface-cli login
```

![img_8.png](images/img_8.png)


#### 创建项目
```shell
cd /workspaces/codespaces-jupyter

# 创建项目 intern_study_L0_4
huggingface-cli repo create intern_study_L0_4

# 克隆到本地
git clone https://huggingface.co/KitHung/intern_study_L0_4
```

#### 提交到远程仓库
```shell
cd intern_study_L0_4
git add .
git commit -m "add:intern_study_L0_4"
git push
```

![img_9.png](images/img_9.png)


## 魔搭社区平台 ModelScope 
### 环境配置
```shell
# 激活环境
conda activate /root/share/pre_envs/pytorch2.1.2cu12.1

# 安装 modelscope
pip install modelscope -t /root/env/maas
pip install numpy==1.26.0  -t /root/env/maas
pip install packaging -t /root/env/maas

# path 设置
export PATH=$PATH:/root/env/maas/bin
export PYTHONPATH=/root/env/maas:$PYTHONPATH

# 创建 demo 目录
mkdir -p /root/ms_demo
```


### 下载指定多个文件
```shell
# internlm2_5-7b-chat
modelscope download \
    --model 'Shanghai_AI_Laboratory/internlm2_5-7b-chat' \
    tokenizer.json config.json model.safetensors.index.json \
    --local_dir '/root/ms_demo'
    
# internlm2_5-1_8b-chat
modelscope download \
    --model 'Shanghai_AI_Laboratory/internlm2_5-1_8b-chat' \
    tokenizer.json config.json model.safetensors.index.json \
    --local_dir '/root/ms_demo'
```

![img_10.png](images/img_10.png)


### 上传模型
```shell
# 模型下载
git clone https://www.modelscope.cn/KitHung/intern_cobuild.git

# 修改文件后上传
git add .
git commit -m "update: colearn page"
git push
```

![img_11.png](images/img_11.png)


## 魔乐社区平台 Modelers
### 下载internlm2_5-chat-1_8b模型
```shell
mkdir /root/ml_demo
cd /root/ml_demo

git clone https://modelers.cn/Intern/internlm2_5-1_8b-chat.git
```

### 安装依赖
```shell
pip install openmind_hub

# 验证安装
python -c "from openmind_hub import repo_info; print(repo_info('PyTorch-NPU/t5_small'))"
```

### 上传文件
```python
from openmind_hub import upload_file

upload_file(
    token="xxx",
    path_or_fileobj="/root/ml_demo/intern_cobuild/index.html",
    repo_id="KitHung/intern_cobuild",
    path_in_repo="index.html"
)
```

![img_12.png](images/img_12.png)